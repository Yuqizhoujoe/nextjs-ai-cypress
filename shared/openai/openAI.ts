// const { Configuration, OpenAIApi } = require("openai");
// openAI
import {
  ChatCompletionRequestMessage,
  Configuration,
  CreateImageRequestResponseFormatEnum,
  CreateImageRequestSizeEnum,
  OpenAIApi,
} from "openai";

// utility
import _ from "lodash";

// error
import createHttpError from "http-errors";

// stream
import {
  createParser,
  ParsedEvent,
  ReconnectInterval,
} from "eventsource-parser";

const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});

const openai = new OpenAIApi(configuration);

export const openAIAPIEnum = {
  CHAT_COMPLETION: "chat_completion",
  GENERATE_IMAGE: "generate_image",
};

type openAIAPIFeatures = (typeof openAIAPIEnum)[keyof typeof openAIAPIEnum];

export async function* getChatResponse(prompt: string) {
  console.log("Sending chat request to OpenAI getChatResponse:", prompt);

  const messages: ChatCompletionRequestMessage[] = [
    { role: "user", content: prompt },
  ];

  const completions = await openai.createChatCompletion({
    model: "gpt-3.5-turbo",
    messages,
    stream: true,
  });

  console.log("openai.createChatCompletion: ", completions);

  const encoder = new TextEncoder();
  const decoder = new TextDecoder();
  const stream = new ReadableStream({
    async start(controller) {
      const createChatCompletionParser = (
        event: ParsedEvent | ReconnectInterval
      ) => {
        if (event.type === "event") {
          const data = event.data;
          if (data === "[DONE]") {
            controller.close();
            return;
          }

          try {
            const json = JSON.parse(data);
            const content = _.get(json, "choices[0].delta.content", "");
            // if \n\n do nothing
            // const lineBreaks = content.match(/\n/g) || [];
            // if (counter < 2 && lineBreaks.length) return;
            const encodeContent = encoder.encode(content);
            controller.enqueue(encodeContent);
          } catch (e) {
            controller.error(e);
          }
        }
      };
      // stream response (SSE) from OpenAI may be fragmented into multiple chunks
      // this ensures we properly read chunks and invoke event for each SSE event stream
      const parser = createParser(createChatCompletionParser);

      // https://web.dev/streams/#asynchronous-iteration
      for await (const chunk of completions.data as any) {
        parser.feed(typeof chunk === "string" ? chunk : decoder.decode(chunk));
      }
    },
  });

  const reader = await stream.getReader();
  let done = false;

  while (!done) {
    const { value, done: doneReading } = await reader.read();
    done = doneReading;
    yield decoder.decode(value);
  }
}

export async function getImageResponse(prompt: string) {
  console.log("Sending request to OpenAI getImageResponse:", prompt);
  console.log(configuration);
  console.log(openai);

  const request = {
    size: CreateImageRequestSizeEnum._512x512,
    response_format: CreateImageRequestResponseFormatEnum.Url,
    n: 6,
    prompt,
  };

  const imageResponse = await openai.createImage(request);
  console.log(imageResponse);

  const imageData = imageResponse.data.data.map((image) => {
    return image.url;
  });
  return imageData;
}

export const handleOepnAIAPI = async (params: {
  type: openAIAPIFeatures;
  data: any;
}) => {
  try {
    const { type, data } = params;

    switch (type) {
      case openAIAPIEnum.GENERATE_IMAGE:
        return getImageResponse(data);
      default:
        throw new createHttpError.NotFound(`${type} feature is not found...`);
    }
  } catch (e) {
    console.error("Error from OpenAI:", e);
    throw e;
  }
};

export const handleOpenAIAsyncGenrator = async (params: {
  type: openAIAPIFeatures;
  data: any;
}) => {
  try {
    const { type, data } = params;

    switch (type) {
      case openAIAPIEnum.CHAT_COMPLETION:
        return getChatResponse(data);
      default:
        throw new createHttpError.NotFound(`${type} feature is not found...`);
    }
  } catch (e) {
    console.error("Error from OpenAI:", e);
    throw e;
  }
};
